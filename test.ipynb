{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "455fd8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_GRAPH_SEARCH_QUERY_PREFIX = \"\"\"\n",
    "WITH node as chunk, score\n",
    "// find the document of the chunk\n",
    "MATCH (chunk)-[:PART_OF]->(d:Document)\n",
    "// aggregate chunk-details\n",
    "WITH d, collect(DISTINCT {chunk: chunk, score: score}) AS chunks, avg(score) as avg_score\n",
    "// fetch entities\n",
    "CALL { WITH chunks\n",
    "UNWIND chunks as chunkScore\n",
    "WITH chunkScore.chunk as chunk\n",
    "\"\"\"\n",
    "VECTOR_GRAPH_SEARCH_ENTITY_QUERY = \"\"\"\n",
    "    OPTIONAL MATCH (chunk)-[:HAS_ENTITY]->(e)\n",
    "    WITH e, count(*) AS numChunks \n",
    "    ORDER BY numChunks DESC \n",
    "    LIMIT {no_of_entites}\n",
    "\n",
    "    WITH \n",
    "    CASE \n",
    "        WHEN e.embedding IS NULL OR ({embedding_match_min} <= vector.similarity.cosine($query_vector, e.embedding) AND vector.similarity.cosine($query_vector, e.embedding) <= {embedding_match_max}) THEN \n",
    "            collect {{\n",
    "                OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){{0,1}}(:!Chunk&!Document&!__Community__) \n",
    "                RETURN path LIMIT {entity_limit_minmax_case}\n",
    "            }}\n",
    "        WHEN e.embedding IS NOT NULL AND vector.similarity.cosine($query_vector, e.embedding) >  {embedding_match_max} THEN\n",
    "            collect {{\n",
    "                OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){{0,2}}(:!Chunk&!Document&!__Community__) \n",
    "                RETURN path LIMIT {entity_limit_max_case} \n",
    "            }} \n",
    "        ELSE \n",
    "            collect {{ \n",
    "                MATCH path=(e) \n",
    "                RETURN path \n",
    "            }}\n",
    "    END AS paths, e\n",
    "\"\"\"\n",
    "\n",
    "VECTOR_GRAPH_SEARCH_QUERY_SUFFIX = \"\"\"\n",
    "   WITH apoc.coll.toSet(apoc.coll.flatten(collect(DISTINCT paths))) AS paths,\n",
    "        collect(DISTINCT e) AS entities\n",
    "   // De-duplicate nodes and relationships across chunks\n",
    "   RETURN\n",
    "       collect {\n",
    "           UNWIND paths AS p\n",
    "           UNWIND relationships(p) AS r\n",
    "           RETURN DISTINCT r\n",
    "       } AS rels,\n",
    "       collect {\n",
    "           UNWIND paths AS p\n",
    "           UNWIND nodes(p) AS n\n",
    "           RETURN DISTINCT n\n",
    "       } AS nodes,\n",
    "       entities\n",
    "}\n",
    "// Generate metadata and text components for chunks, nodes, and relationships\n",
    "WITH d, avg_score,\n",
    "    [c IN chunks | c.chunk.text] AS texts,\n",
    "    [c IN chunks | {id: c.chunk.id, score: c.score}] AS chunkdetails,\n",
    "    [n IN nodes | elementId(n)] AS entityIds,\n",
    "    [r IN rels | elementId(r)] AS relIds,\n",
    "    apoc.coll.sort([\n",
    "        n IN nodes |\n",
    "        coalesce(apoc.coll.removeAll(labels(n), ['__Entity__'])[0], \"\") + \":\" +\n",
    "        coalesce(\n",
    "            n.id,\n",
    "            n[head([k IN keys(n) WHERE k =~ \"(?i)(name|title|id|description)$\"])],\n",
    "            \"\"\n",
    "        ) +\n",
    "        (CASE WHEN n.description IS NOT NULL THEN \" (\" + n.description + \")\" ELSE \"\" END)\n",
    "    ]) AS nodeTexts,\n",
    "    apoc.coll.sort([\n",
    "        r IN rels |\n",
    "        coalesce(apoc.coll.removeAll(labels(startNode(r)), ['__Entity__'])[0], \"\") + \":\" +\n",
    "        coalesce(\n",
    "            startNode(r).id,\n",
    "            startNode(r)[head([k IN keys(startNode(r)) WHERE k =~ \"(?i)(name|title|id|description)$\"])],\n",
    "            \"\"\n",
    "        ) + \" \" + type(r) + \" \" +\n",
    "        coalesce(apoc.coll.removeAll(labels(endNode(r)), ['__Entity__'])[0], \"\") + \":\" +\n",
    "        coalesce(\n",
    "            endNode(r).id,\n",
    "            endNode(r)[head([k IN keys(endNode(r)) WHERE k =~ \"(?i)(name|title|id|description)$\"])],\n",
    "            \"\"\n",
    "        )\n",
    "    ]) AS relTexts,\n",
    "    entities\n",
    "// Combine texts into response text\n",
    "WITH d, avg_score, chunkdetails, entityIds, relIds,\n",
    "    \"Text Content:\\n\" + apoc.text.join(texts, \"\\n----\\n\") +\n",
    "    \"\\n----\\nEntities:\\n\" + apoc.text.join(nodeTexts, \"\\n\") +\n",
    "    \"\\n----\\nRelationships:\\n\" + apoc.text.join(relTexts, \"\\n\") AS text,\n",
    "    entities\n",
    "RETURN\n",
    "   text,\n",
    "   avg_score AS score,\n",
    "   {\n",
    "       length: size(text),\n",
    "       source: COALESCE(CASE WHEN d.url CONTAINS \"None\" THEN d.fileName ELSE d.url END, d.fileName),\n",
    "       chunkdetails: chunkdetails,\n",
    "       entities : {\n",
    "           entityids: entityIds,\n",
    "           relationshipids: relIds\n",
    "       }\n",
    "   } AS metadata\n",
    "\"\"\"\n",
    "\n",
    "VECTOR_GRAPH_SEARCH_ENTITY_LIMIT = 40\n",
    "VECTOR_GRAPH_SEARCH_EMBEDDING_MIN_MATCH = 0.3\n",
    "VECTOR_GRAPH_SEARCH_EMBEDDING_MAX_MATCH = 0.9\n",
    "VECTOR_GRAPH_SEARCH_ENTITY_LIMIT_MINMAX_CASE = 20\n",
    "VECTOR_GRAPH_SEARCH_ENTITY_LIMIT_MAX_CASE = 40\n",
    "\n",
    "VECTOR_GRAPH_SEARCH_QUERY = VECTOR_GRAPH_SEARCH_QUERY_PREFIX+ VECTOR_GRAPH_SEARCH_ENTITY_QUERY.format(\n",
    "    no_of_entites=VECTOR_GRAPH_SEARCH_ENTITY_LIMIT,\n",
    "    embedding_match_min=VECTOR_GRAPH_SEARCH_EMBEDDING_MIN_MATCH,\n",
    "    embedding_match_max=VECTOR_GRAPH_SEARCH_EMBEDDING_MAX_MATCH,\n",
    "    entity_limit_minmax_case=VECTOR_GRAPH_SEARCH_ENTITY_LIMIT_MINMAX_CASE,\n",
    "    entity_limit_max_case=VECTOR_GRAPH_SEARCH_ENTITY_LIMIT_MAX_CASE\n",
    ") + VECTOR_GRAPH_SEARCH_QUERY_SUFFIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf79b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_neo4j import Neo4jVector\n",
    "from langchain_neo4j import Neo4jGraph\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "from langchain_classic.retrievers.document_compressors import EmbeddingsFilter, DocumentCompressorPipeline\n",
    "from langchain_classic.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "\n",
    "\n",
    "graph = Neo4jGraph()\n",
    "embedding_function = HuggingFaceEmbeddings(model_name=r\"E:\\my_github_work\\graph_builder\\backend\\local_model\\Qwen\\Qwen3-Embedding-0___6B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e4b2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = Neo4jVector.from_existing_graph(\n",
    "    embedding=embedding_function,\n",
    "    index_name=\"vector\",\n",
    "    retrieval_query=VECTOR_GRAPH_SEARCH_QUERY,\n",
    "    graph=graph,\n",
    "    search_type=\"hybrid\",\n",
    "    node_label=\"Chunk\",\n",
    "    embedding_node_property=\"embedding\",\n",
    "    text_node_properties=[\"text\"],\n",
    "    keyword_index_name=\"keyword\",\n",
    ")\n",
    "retriever = vector.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\n",
    "        'k': 5,  # bug 应该是 k\n",
    "        'effective_search_ratio': 5,\n",
    "        'score_threshold': 0.5\n",
    "    }\n",
    ")\n",
    "splitter = TokenTextSplitter(chunk_size=3000, chunk_overlap=0)\n",
    "embeddings_filter = EmbeddingsFilter(\n",
    "    embeddings=embedding_function,\n",
    "    similarity_threshold=0.10\n",
    ")\n",
    "pipeline_compressor = DocumentCompressorPipeline(\n",
    "    transformers=[splitter, embeddings_filter]\n",
    ")\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=pipeline_compressor, base_retriever=retriever\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
